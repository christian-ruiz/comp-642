{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation & Hyperparameter Tunning\n",
    "\n",
    "In this exercie, we will take a look at the implementation of multiple model evaluation methods we've mentioned in class and answer some questions related to the plot and the learning curve. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Implementation VS Non-Pipeline Implementation\n",
    "\n",
    "In this section we provide you the code to do classification on \"breast cancer\" dataset without using Pipeline.  You will need to follow the code snippet covered in lecture and finish the code to do the classification with Pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('https://archive.ics.uci.edu/ml/''machine-learning-databases''/breast-cancer-wisconsin/wdbc.data',header=None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encode the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation without Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stder = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_train_std = stder.fit_transform(X_train)\n",
    "X_test_std = stder.transform(X_test)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_pca, y_train)\n",
    "y_pred = lr.predict(X_test_pca)\n",
    "\n",
    "print('Test Accuracy: %.3f' % lr.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO :: Implement the above task by using Pipeline. Your implementation should have the same test accuracy as the \n",
    "# implementation without Pipeline. 9 lines of code expected. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation without Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "X_train_std = stder.fit_transform(X_train)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "\n",
    "kfold= StratifiedKFold(n_splits=10,random_state=1).split(X_train_std, y_train)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_pca[train], y_train[train])\n",
    "    score = lr.score(X_train_pca[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,np.bincount(y_train[train]), score))\n",
    "    print('CVaccuracy: %.3f +/-%.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold= StratifiedKFold(n_splits=10,random_state=1).split(X_train, y_train)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,np.bincount(y_train[train]), score))\n",
    "    print('CVaccuracy: %.3f +/-%.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "Did you notice that the final CVaccuracy of implementation with Pipeline and without Pipeline is different? I made a common mistake in cross validation without Pipeline code. Can you help me to fix this bug and explain why it is a problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO :: Correct the implementation without pipeline, 13-20 lines of code expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation VS Nested Cross Validation\n",
    "\n",
    "The following code uses SVM model with rbf kernel to classifiy the iris dataset. It evaluates the model by using both cross validation and nested cross validation.  It also plots the evaluation score. Read and execute the following code section and answer the question below. (hint : the sklearn document can help you to understand the code better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100],\n",
    "          \"gamma\": [.01, .1]}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n",
    "    clf.fit(X_iris, y_iris)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))\n",
    "\n",
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on Iris Dataset\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")\n",
    "\n",
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "The above plots show the score and score difference of cross validation versus nested cross validation.  What obervation can be made in terms of the score of the two methods. Why does that happen? Which one do you think is a better way to evaluate the performance of the model? Why do you think so?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Read the code above especially in the loop for each trial. Explain what does this line : nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv) do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
