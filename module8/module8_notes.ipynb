{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptrons | Lecture 1\n",
    "\n",
    "A perceptron (threshold unit) can learn anything that it can represent (i.e. anything separable with a hyperplane)\n",
    "\n",
    "How could we use this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Units & Weight Updates | Lecture 2\n",
    "\n",
    "## Learning with Hidden Units\n",
    "\n",
    "* Networks without hidden units are very limited in the input-output mappings they can model\n",
    "    * more layers of linear units do not help. Its still linear\n",
    "    * fixed output non-linearities are not enough\n",
    "\n",
    "* We need multiple layers of adaptive non-linear hidden units. This gives us a universal approximator. But how can we train such nets?\n",
    "    * We need an efficient way of adapting all the weights not just the last layer. This is hard. Learning the weights going into hidden units is equivalent to learning features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning by adjusting weights\n",
    "\n",
    "* Randomly adjust one weight and see if it improves performance. If so, save the change\n",
    "    * very inefficient. We need to do multiple froward passes. On a representative set of training data just to change one weight.\n",
    "    * towards the end of learning, large weight adjustments will nearly always make things worse.\n",
    "\n",
    "* We could randomly adjust all the weights in parallel and correlate the performanec gain with the weight changes\n",
    "    * Not any better because we need lots of trials to \"see\" the effect of changing one weight through the noise created by all the others.\n",
    "\n",
    "Learning the output to hidden weights is easy. Learning the input to hidden weights is hard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithms for MLP\n",
    "\n",
    "* similar to the perceptron learning algorithm\n",
    "    * one minor difference is that we may have several outputs, so we have an output vector h_w(x) rather than a single value, and each example has an output vector y.\n",
    "    * the major difference is that, whereas the error y - h_w at the perceptron output layer is clear, the rror at the hidden layers seems mysterious because the training data does not way what value the hidden nodes should have\n",
    "\n",
    "We can back-propagate the error from the output layer to the hidden layers. the back-propagation process emerges directly from a derivation of the overall error gradient.\n",
    "\n",
    "uses derivation of gradiaent to update weights\n",
    "\n",
    "## The idea behind backpropagation\n",
    "\n",
    "* we don't know what the hidden units ought to do, but we can compute how fast the error changes as we change a hidden activity\n",
    "    * instead of using desired activities to train the hidden units, use error derivatives w.r.t. hidden activities\n",
    "    * each hidden activity can affect many output units and can therfore have many separate effects on the error. These effects must be combined\n",
    "    * we can compute error derivatives for all the hidden units efficiently\n",
    "    * once we have the error derivatives for the hidden activities, its easy to get the error derivatives for the weights going inot a hidden unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "* gradient descent over entire network weight vector\n",
    "* easily generalized to arbitrary directed graphs\n",
    "* will find a local, not necessarily global error minimum - in practice often works well (can be invoked multiple times with different initial weights)\n",
    "often include weight momentum term\n",
    "\n",
    "$$\\Delta w_{i, j}(n) = \\eta \\text{ } \\delta \\text{ } x_{i,j} + \\alpha \\text{ } \\delta \\text{ } w_{i,j}(n-1)$$\n",
    "\n",
    "* minimizes error training examples\n",
    "* training can be slow typical 1000 - 10000 iterations\n",
    "* using network after training is fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence of Backprop\n",
    "\n",
    "Gradient descent to some local minimum perhaps not global minimum\n",
    "\n",
    "* add momentum term: $\\Delta W_{k,i}(n)$ - $\\Delta w_{i, j}(n) = \\eta \\text{ } \\delta \\text{ } x_{i,j} + \\alpha \\text{ } \\delta \\text{ } w_{i,j}(n-1)$ with $\\gamma \\epsilon [0, 1]$\n",
    "\n",
    "* stochastic gradient descent\n",
    "* train multiple nets with different initial weights\n",
    "\n",
    "Nature of convergence\n",
    "\n",
    "* initialize weights newar zero\n",
    "* therefore, initial networks near-linear\n",
    "* increasingly non-linear functions possible as training progresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backpropagation algorithm\n",
    "\n",
    "* initialize each $w_i$ to some small random value\n",
    "* until the termination condistion is met, Do\n",
    "    - for each training example $<(x_i ... x_n), t>$ do\n",
    "        - input the instance $(x_1 ... x_n)$ to the network and compute the network outputs $y_k$\n",
    "        - for each output unit k\n",
    "            - $\\delta = y_k(1-y_k)(t_k - y_k)$\n",
    "        - for each higgen unit h\n",
    "            - $\\delta = y_h(1-y_h)\\sum_k w_{h,k} \\Gamma_k$\n",
    "        - for each network weight $w_{i,j}$ Do\n",
    "            - $w_{i,j} = w_{i,j} + \\Delta w_{i,j}$ where $\\Delta w_{i,j} = \\eta \\delta_j x_{i,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristics & Expressivity | Lecture 3\n",
    "\n",
    "taking a look at how we can speed up convergence or multi layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristics to speed convergence\n",
    "\n",
    "* to speed the convergence of the back-propagation algorithm the following heuristics are applied:\n",
    "    * H1: use sequential (online) vs bactch update\n",
    "    * H2: maximize information content\n",
    "        * use examples that produce largest error\n",
    "        * use example which very different from all the previous ones\n",
    "    * H3: use an antisymmetric activation function, such as the hyperbolic tangent. Antisymmetric means: $\\phi (-x) = - \\phi (x)$\n",
    "    * H4: use different target values inside a smaller range, different from asymptotic values of the sigmoid\n",
    "\n",
    "* H5: normaize the inputs: \n",
    "    * create zero-mean variables\n",
    "    * decorrelate the variables\n",
    "    * scale the variables to have covariances approximately equal\n",
    "* H6: initialize properly the weights. Use a zero mean distribution with variance of: $\\sigma_w = \\frac{1}{\\sqrt{m}}$\n",
    "    * where m is the number of connections arriving to a neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjsting Learning Rates\n",
    "\n",
    "* R1: every adjustable parameter should have it's own learning rate\n",
    "* R2: every learning rate should be allowed to adjust from one iteration to the next\n",
    "* R3: when the derivative of the cost fucntion wrt a weight has the same algebraic sign for several consecutive iteration so fthe algortihm, the learing rate for that particular weight should be increased\n",
    "* R4: when the algebraic sign of the derivative above alternates for several consecutive iterations of the algorithm the learning rate should be decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Comments\n",
    "\n",
    "* empirical knowledges shows that the number of data pairs that are needed in order to achieve a givene error level $\\epsilon$ is:\n",
    "\n",
    "$$ N = o(\\frac{W}{\\epsilon})$$\n",
    "\n",
    "* where W is the total number of adjustable parameters of the model. There is mathematical support for this observation (but we will not analyse this further)\n",
    "* there is the curse of dimensionality for approximating functions in high-dimensional spaces\n",
    "* it is theoretically justified to use two hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressiveness of multi-layer feedforward networks\n",
    "\n",
    "Boolean functions:\n",
    "* every boolean function can be represented by a network with single hidden layer\n",
    "* but might require exponential (in number of inputs) hidden units\n",
    "\n",
    "Continuous functions:\n",
    "* every bounded continuous function can be apporoximated with arbitrarily small error, by network with single hidden layer\n",
    "\n",
    "Any function can be approximated to arbitrary accuracy by a netowrk with two hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long should you train the net?\n",
    "\n",
    "* the goal is to achieve a balance between correct responses for the training patterns and correct responses for new patterns. (that is, a balance between memorization and generalization)\n",
    "\n",
    "* if you train the net for too long, then you run the risk of overfitting\n",
    "\n",
    "* select number of training iterations via cross-validation on holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataflow programming & TensorFlow | Lecture 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
